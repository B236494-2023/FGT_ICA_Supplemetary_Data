---
output:
  pdf_document: default
  html_document: default
---

    title: "Affymetrix Microarray Minimal pipeline"
    author: "Simon Tomlinson 10/02/2021"
    output: html_document

```{r setup, include=FALSE}
#This is basically the R code from FGT_T3, FGT_T4 and FGT_T5 combined into one script.
#Running the code in RStudio or MobaXterm is easy-load and run or source the file on one of the servers
#Modifying the code requires that you understand the R script and the FGT classes!
#Note that this code often uses the input files directly from /shared_files.  If you do not intend to edit a copy is not needed
#We do not need to load data between the tutorials - we just use the same data across the whole script

#Problems (features that might be improved)
#
#The code has no interactivity or feedback to the user
#The code has some duplication that could be addressed using a better design!
#Comments are messy and the code layout is poor in places
#Note that there are enhancements given in class that are not in the skeleton such as 
#SimpleAffy, PMA calls, targets file use etc
#Most of the missing features would results in better outputs and more sustainable code
#The code will plot figures one after another, OK in RStudio but for SSH sessions they should be saved

#But the skeleton code does run and reproduce the class practical!!




knitr::opts_chunk$set(echo = TRUE)
```

# B236494 - Affymetrix Microarray Analysis Basic Workflow

##Load the required libraries & load the files for the workflow

```{r libload, echo=TRUE}
library(limma)
library(affy)
library(annotate)
library(mouse4302.db)# load chip-specific annotation
library(ggplot2)

#install.packages("scatterplot3d",repo="http://cran.ma.imperia#l.ac.uk")
#Then load the library
library(scatterplot3d)
```

## Load the main data- commented code is just for information

```{r dataload, echo=TRUE}
# Load the target file into an AnnotatedDataFrame object
adf<-read.AnnotatedDataFrame("B236494_edited_final_targets_file.txt",header=TRUE,row.names=1,as.is=TRUE)
# Load the expression values of all the CEL files in the targets file
mydata <- ReadAffy(filenames=pData(adf)$FileName,phenoData=adf)

# Or just to quickly load all CEL files in the R working directory
mydata <- ReadAffy()
# View a summary of the example data
mydata
```

## Build Quality Control Plots

```{r qc_plots1, echo=FALSE}

# Quality control plots
hist(mydata)

# And a boxplot with different colour per sample group
colours <- c(rep("yellow",3),rep("red",3))

boxplot(mydata, col=colours, las=2)

```

## Normalise the data using RMA

```{r normalise, echo=FALSE}

eset <- rma(mydata)
eset
# To obtain a matrix of the expression values, use exprs() 
values <- exprs(eset)

```

## Plot Normalised Data

```{r plot_normalised, echo=FALSE}


# Boxplot to observe the results of normalisation
# Notice differences with the boxplot from the raw data
boxplot(values, col=colours,las=2)

# MA plot of the samples 1 and 4
mva.pairs(values)
# The same plot for the non-normalised raw data
# Note that the mva.pairs call below only plots a few of the  #samples – you may wish to plot them all but this is slow
mva.pairs(pm(mydata))

```

## Plot Heatmap

```{r heatmap_normalised, echo=FALSE}

# To facilitate interpretation, let’s replace the columns # # header,currently
# displaying the filename, to show the name of each sample 
# (if you have a targets file)
colnames(values) <- rownames(pData(adf))
# Performs hierarchical clustering with average linkage based on
# Pearson’s Correlation Coefficient
hc<-hclust(as.dist(1-cor(values, method="pearson")), method="average")
plot(hc)
```

## Perform PCA

```{r pca_normalised, echo=FALSE}

### removed scale=T, i think its already normalised
pca <- prcomp(t(values))
# Plot the PCA results

s3d<-scatterplot3d(pca$x[,1:3], pch=19, color=rainbow(1))
s3d.coords <- s3d$xyz.convert(pca$x[,1:3])
text(s3d.coords$x, s3d.coords$y, labels = colnames(values),pos = 3,offset = 0.5)
```

## Perform fold filtering

```{r fold_filtering, echo=TRUE}

#obtaining a matrix of expression values
exprsvals <- exprs(eset)
#RMA outputs log2 data while MAS5 outputs linear data
#To convert from log…
exprsvals10 <-2^exprsvals
#check conversion
exprsvals[1:10,]
#converted
exprsvals10[1:10,]

#More fold filtering
#check order of sample names
mysamples <- sampleNames(eset)
#display the list
mysamples
#it is useful to obtain a vector of ProbeIDs here
probesets <- probeNames(mydata)
#display the first 10 ProbeSets
probesets[1:10]

#Build final fold table
#Calculate the means
#Note mean of the log is not the same as the log of the mean!!
Arid1a_f_f.mean <- apply(exprsvals10[,c("GSM4072331_AF1_Mouse430_2_.CEL", "GSM4072332_AF2_Mouse430_2_.CEL","GSM4072333_AF3_Mouse430_2_.CEL")],1,mean)

Arid1a_d_d.mean <- apply(exprsvals10[,c("GSM4072334_AD1_Mouse430_2_.CEL", "GSM4072335_AD2_Mouse430_2_.CEL","GSM4072336_AD3_Mouse430_2_.CEL")],1,mean)
#calculate some fold changes
Arid1a_fold_change <- Arid1a_f_f.mean/Arid1a_d_d.mean
##ES_iPS_OK <-ES.mean /iPS_OK.mean
##ES_iPS_4F <-ES.mean /iPS_4F.mean
##ES_NSC <-ES.mean /NSC.mean

#build a summary table to hold all the data

##all.data= cbind(ES.mean,iPS_OK.mean,iPS_4F.mean, NSC.mean, ES_iPS_OK,ES_iPS_4F, ES_NSC)
all.data= cbind(Arid1a_fold_change)
#check the column names
colnames(all.data)
#write the table of means as an output
write.table(all.data,file="B236494_group_means.txt", quote=F,
sep="\t",col.names=NA)
```

## Beginning statistical analysis

```{r limma_stats, echo=TRUE}

#Check original sample order
sampleNames(eset)
#Rename the samples
sampleNames(eset) <-
c("GSM4072331_AF1_Mouse430_2_.CEL","GSM4072332_AF2_Mouse430_2_.CEL","GSM4072333_AF3_Mouse430_2_.CEL","GSM4072334_AD1_Mouse430_2_.CEL","GSM4072335_AD2_Mouse430_2_.CEL","GSM4072336_AD3_Mouse430_2_.CEL")
#Check the samples have renamed
sampleNames(eset)

```

```{r building_annotation, echo=TRUE}
##Building annotation for differential gene identification
#establish annotation for MOE430v2
#which annotation do we need
#modified from #http://gettinggeneticsdone.blogspot.co.uk/2012/01/annotating-limma-#results-with-gene.html

eset@annotation


#packages in the annotation package
ls("package:mouse4302.db")

#build an annotation table
ID <- featureNames(eset)
Symbol <- getSYMBOL(ID, "mouse4302.db")
Name <- as.character(lookUp(ID, "mouse4302.db", "GENENAME"))
tmp <- data.frame(ID=ID, Symbol=Symbol, Name=Name, stringsAsFactors=F)
tmp[tmp=="NA"] <- NA #fix padding with NA characters 
#assign as feature data of the current Eset
fData(eset) <- tmp

# Check for rows that don’t have an EntrezID
missing_entrezid_count <- sum(is.na(fData(eset)$ENTREZID))

print(missing_entrezid_count)

```

## Statistical analysis using Limma

```{r limma_statistical_analysis, echo=TRUE}

#Build the design matrix
design <- model.matrix(~-1+factor(c(1,1,1,2,2,2)))
colnames(design) <- c("Arid1a_f_f","Arid1a_d_d")
#Check it makes sense
sampleNames(eset)
#output the design matrix
design

#This instructs Limma which comparisons to make
contrastmatrix <- makeContrasts(Arid1a_f_f-Arid1a_d_d,levels=design)
contrastmatrix

#issue these commands to fit the model
#and make the contrasts
fit <- lmFit(eset, design)

fit2 <- contrasts.fit(fit, contrastmatrix)

#this last part essentially moderates the t-statistic using 
#the borrowed variance approach described in class
fit2 <- eBayes(fit2)

#get the results
topTable(fit2,coef=1,adjust="fdr")
myresults <-topTable(fit2,coef=1, adjust="fdr", number=nrow(eset))
write.table(myresults,"B236494_myresults.txt")

#make a venn diagram
clas <- classifyTestsF(fit2)
vennDiagram(clas)
```

## Carry out Functional Enrichment analysis

```{r functional_enrichment, echo=TRUE}

Mm.H <- readRDS("/shared_files/MSigDB/Mm.h.all.v7.1.entrez.rds") 

#Check that you have the required objects
ls()

#Show the full contents of the annotation package
ls("package:mouse4302.db")

#Show the annotation keys in this database
keytypes(mouse4302.db) 

sampleNames(eset)
```

## Process annotation for functional enrichment

```{r process_annotation_for_enrichment, echo=TRUE}

#Here we select from the annotation a number of keys with the primary key being PROBEID
res <- select(mouse4302.db, keys = rownames(eset), columns = c("ENTREZID", "ENSEMBL","SYMBOL"), keytype="PROBEID")
#View the top of the table
head(res)
#find the index of each row of the expression set in the #annotation object res
idx <- match(rownames(eset), res$PROBEID)
#Use the index to set the phenotypic data in the ExpressionSet
fData(eset) <- res[idx, ]
head(fData(eset), 10)
#Find all rows that don’t have an EntrezID and remove then
eset_t<-eset[is.na(fData(eset)$ENTREZID)==0,]
```

## Functional Enrichment Analysis

```{r convert_indicex, echo=TRUE}

#convert to indexes
H.indices <- ids2indices(Mm.H,fData(eset_t)$ENTREZID)
#Pick the most suitable enrichment analysis tool to find #enrichment signatures in the data and run this tool So:-

#I just run mroast here as an example- justify the selection of this method!

#if you want to run mroast
results_mroast <-mroast(eset_t,index=H.indices,design=design,contrast=contrastmatrix[,1],adjust.method = "BH")
#if you want to run camera
results_camera <-camera(eset_t,index=H.indices,design=design,contrast=contrastmatrix[,1],adjust.method = "BH")
#if you want to run romer
results_romer <-romer(eset_t,index=H.indices,design=design,contrast=contrastmatrix[,1],adjust.method = "BH")
#View the results
results_mroast

#Use help for other parameters. Note we might decide to use #exactly the same model as our differential gene analysis for #the enrichment analysis- in this case we can extract it from #the fit
#sv <- squeezeVar(fit$sigma^2,df=fit$df.residual)

write.table(results_mroast,"B236494_final_enrichment.txt",sep="\t")
#You can then examine the results in “enrichment.txt”.  It is a text file.  It can be downloaded to view in a spreadsheet such as Excel.
```

## Session Information

```{r session_info, echo=TRUE}

sessionInfo()

```

# Selecting Differentially expressed genes in the dataset

```{r Volcano Plot, echo=TRUE, fig.cap="Volcano plot of differential expression"}

# Extracting the table of results
volcano_plot_results <- topTable(fit2, coef=1, number=Inf, sort.by="none", p.value=1)

# Creating the volcano plot
#with(results, plot(logFC, -log10(P.Value), pch=20, main="Volcano Plot", xlab="Log Fold Change", ylab="-Log10 P-value"))
with(volcano_plot_results, {
    plot(logFC, -log10(P.Value), pch=20, col=ifelse(P.Value < 0.05 & abs(logFC) > 1, "red", "black"), main="Volcano Plot", xlab="Log Fold Change", ylab="-Log10 P-value")
    abline(h=-log10(0.05), col="blue")
    abline(v=c(-1, 1), col="green")
})


# Adding a horizontal line for P-value threshold (example threshold P=0.05)
abline(h=-log10(0.05), col="blue")

# Adding vertical lines for log fold changes thresholds (example thresholds logFC > |1|)
abline(v=c(-1, 1), col="red")

ggplot(volcano_plot_results, aes(x=logFC, y=-log10(P.Value), color=(P.Value < 0.05 & abs(logFC) > 1))) +
    geom_point(alpha=0.5) +
    scale_color_manual(values=c("black", "red")) +
    labs(title="Volcano Plot", x="Log Fold Change", y="-Log10 P-value") +
    geom_hline(yintercept=-log10(0.05), color="blue", linetype="dashed") +
    geom_vline(xintercept=c(-1, 1), color="green", linetype="dashed")


```

```{r volcano_plot_limma_basic, echo=TRUE, fig.cap="Volcano plot of differential expression using limma"}

# Using the volcanoplot function to create the plot
volcanoplot(fit2, coef=1, style="p-value", highlight=10,
            names=rownames(fit2$coefficients), 
            xlab="Log2 Fold Change", ylab="-Log10 P-value",
            pch=20, cex=1, main="Volcano Plot")


```
